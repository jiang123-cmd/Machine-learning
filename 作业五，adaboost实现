import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import math

from IPython.core import debugger
debug = debugger.Pdb().set_trace

%matplotlib inline


# 问题描述：实现SVM的SMO优化算法，训练给定数据集，并测试和可视化结果。对比与sklearn科学计算工具包的svm方法效果。


# 鸢尾花(iris)数据集
# 数据集内包含 3 类共 150 条记录，每类各 50 个数据，
# 每条记录都有 4 项特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度，
# 可以通过这4个特征预测鸢尾花卉属于（iris-setosa, iris-versicolour, iris-virginica）中的哪一品种。
# 这里只取前100条记录，两项特征，两个类别。

def create_data():
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    data = np.array(df.iloc[:100, [0, 1, -1]])
    for i in range(len(data)):
        if data[i,-1] == 0:
            data[i,-1] = -1
    # print(data)
    return data[:,:2], data[:,-1]

X, y = create_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=65)

x=[0,1,2,3,4,5,6,7,8,9]
x=np.array(x)
y=[1,1,1,-1,-1,-1,1,1,1,-1]
y=np.array(y)
class Adaboost():
    def __init__(self):
        self=self
    #求阈值,误差率,Gm(x)
    def threshold(self, weight,y_train):
        self.long=len(weight)
        self.distinguish=[1,-1]
        self.result=[]
        self.v_best=0
        self.error_rate=0
        self.error_rate_min=1
        self.v=0
        self.c=0
        for i in range(self.n):
            self.result+=[0]
        for i in range(self.long-1):
            self.error_rate=0
            self.v=i+0.5
            #分类后的标签值
            for j in range(i):
                self.result[j]=y_train[i]
            for j in range(i+1,self.long):
                self.result[j]=y_train[i+1]
            #误差率
            for m in range(self.long):
                if self.result[m]!=y_train[m]:
                    self.error_rate=self.error_rate+weight[m]
            #最小误差率
            if (self.error_rate<self.error_rate_min):
                self.c+=1
                self.error_rate_min=self.error_rate
                self.v_best=self.v
                #self.result_best=self.result #基本分类器
                self.distinguish[0]=y_train[i]
                self.distinguish[1]=-self.distinguish[0]
        #print("v: ",self.v_best)
        for j in range(int(self.v_best-0.5)):
            self.result[j]=y_train[(int(self.v_best-0.5))]
        #print("result",y_train[(int(self.v_best-0.5))])
        for j in range(int(self.v_best+0.5),self.long):
            self.result[j]=y_train[int(self.v_best+0.5)]
        return self.v_best,self.error_rate_min,self.result,self.distinguish
    
    
    #求G(x)的系数apha,对的
    def apham(self,error_rate):
        self.apha=(math.log((1-error_rate)/error_rate))/2
        return self.apha
    
    
    #求新的权值分布
    def omiga(self,weight_1,apha,y_train,Gm_1):
        self.weight_2=[]
        self.Z=0
        self.long=len(weight_1)
        for i in range(self.long):
            self.Z=self.Z+weight_1[i]*math.exp(-apha*y_train[i]*Gm_1[i])
        for i in range(self.long):
            self.weight_2+=[weight_1[i]*math.exp(-apha*y_train[i]*Gm_1[i])/self.Z]
        return self.weight_2
    
    
    def train(self,x,y):
        self.n=len(y)
        self.Threshol=[]#阈值
        self.weight=[]#权重
        self.apha=[]
        self.Gm=[]
        self.Z=[]
        self.distinguish=[]#两种情况：[1,-1],[-1,1]
        self.distinguish_sum=[]
        self.error_quantity=1
        self.m=0 #基本分类器的标号
        self.result_final=[]#分类结果
        self.result_finally=[]
        self.frequency=0
        for i in range(self.n):
            self.weight+=[round(1/self.n,4)]
            self.result_final+=[0]
            self.result_finally+=[0]
        #更新的只有权重，通过权重和y的函数产生Gm,权重是为了求apha的，与最终结果无关
        while (self.error_quantity!=0):
            
            self.error_quantity=0
            self.Threshol_1,self.error_rate,self.Gm,self.distinguish=self.threshold(self.weight,y)
            
            self.Threshol+=[self.Threshol_1]
            self.distinguish_sum+=[self.distinguish]
            self.apha+=[self.apham(self.error_rate)]
            #print("w_1: ",np.array(self.weight))
            #print("apha: ",self.apha[self.m])
            #print("Gm",np.array(self.Gm))
            #print("y: ",y)
            self.weight=self.omiga(np.array(self.weight),self.apha[self.m],y,np.array(self.Gm))
            #print("w: ",self.weight)
            #i是基本分类器的个数，从1开始，每个基本分类器apha*Gm
            #print("m:",self.m)
            #print("apha: ",self.apha[self.m])
            #print("distinguish: ",self.distinguish[0])
            
            for j in range(int(self.Threshol[self.m]+0.5)):
                self.result_final[j]=self.apha[self.m]*self.distinguish[0]+self.result_final[j]
                    #print("result_float: ",self.result_final[j])
            for j in range(int(self.Threshol[self.m]+0.5),self.n):
                self.result_final[j]=self.apha[self.m]*self.distinguish[1]+self.result_final[j]
            #print("Threshol: ",int(self.Threshol[self.m]+0.5))
            #print("n",self.n)
            
            
            for i in range(self.n):
                if self.result_final[i]<0:
                    self.result_finally[i]=-1
                else:
                    self.result_finally[i]=1
                if (self.result_finally[i]!=y[i]):
                    self.error_quantity+=1
            #print("result",self.result_final)
            print("error_quantity: ",self.error_quantity)
            
            #print("错误分类的数量：",self.error_quantity)
            self.m+=1
            self.frequency+=1
            #print("基本分类器数量：",self.frequency)
            if (self.frequency>=100):#最多20个基本分类器
                break
        return self.apha,self.Threshol,self.distinguish_sum,self.result_finally
            
adaboost=Adaboost()
apha=[]
Threshol=[]
distinguish_sum=[]
result=[]
apha,Threshol,distinguish_sum,result=adaboost.train(X_train,y_train)
print("apha: ",apha)
print("Threshol: ",Threshol)
print("distinguish_sum: ",distinguish_sum)


print(np.array(result))
for i in range(len(result)):
    y_train[i]=result[i]
    plt.scatter(X_train[y_train==1,0], X_train[y_train==1,1], marker='o', c='r', label='1') 
    plt.scatter(X_train[y_train==-1,0], X_train[y_train==-1,1], marker='o', c='b', label='-1') 
